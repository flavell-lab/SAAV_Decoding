{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: XLA_PYTHON_CLIENT_PREALLOCATE=true\n",
      "env: XLA_PYTHON_CLIENT_MEM_FRACTION=0.2\n",
      "env: JAX_DEBUG_NANS=true\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env XLA_PYTHON_CLIENT_PREALLOCATE=true\n",
    "%env XLA_PYTHON_CLIENT_MEM_FRACTION=0.2\n",
    "%env JAX_DEBUG_NANS=true\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from cepnem_jax import h5_to_dict, dict_to_h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define some constants used in importation of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_STD = 0.06030961137253011\n",
    "vT_STD = 0.9425527026496543\n",
    "θh_STD = 0.49429038957075727\n",
    "P_STD = 1.2772001409506841"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define paths for each project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prj_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRJ_RIM\n",
    "\n",
    "prj_data[\"prj_rim\"] = {\n",
    "    \"processed_h5_directory\": \"/data3/prj_rim/processed_h5\", # Directory containing the processed h5 files\n",
    "    \"neuropal_file\": \"/data3/prj_rim/Decoding_Data/Aggregated_Traces_h5/dict_neuropal_label.h5\", # File containing the neuropal labels\n",
    "    \"octanol_directory\": \"/data3/prj_rim/OctanolEncounters\", # File containing the octanol events\n",
    "    \"structured_dict\": h5_to_dict(\"/data3/prj_rim/Decoding_Data/Structured_Data_Info.h5\")\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PRJ_KFC\n",
    "\n",
    "# prj_data[\"prj_kfc\"] = {\n",
    "#     \"processed_h5_directory\": \"/store1/prj_kfc/data/processed_h5\", # Directory containing the processed h5 files\n",
    "#     \"neuropal_file\": \"/store1/prj_jax/Aggregated_Traces_h5/dict_neuropal_label_prj_kfc.h5\", # File containing the neuropal labels\n",
    "#     \"structured_dict\": h5_to_dict(\"/store1/prj_kfc/Structured_Data_Info.h5\")\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_comb = {}\n",
    "data = {}\n",
    "\n",
    "for project, prj_vals in prj_data.items():\n",
    "    ds_of_interest = [ds for ds, value in prj_vals[\"structured_dict\"].items() if set([\"wt\"] if project==\"prj_rim\" else [\"baseline\", \"neuropal\"]).issubset(set(value[\"Tags\"]))]\n",
    "    result_dict = h5_to_dict(prj_vals[\"neuropal_file\"]) # Load the neuropal labels\n",
    "    \n",
    "    for neuron in result_dict.keys():\n",
    "        if(neuron == 'glia' or neuron == 'UNKNOWN' or '?' in neuron): # Ignore glia and unknown neurons\n",
    "            continue\n",
    "            \n",
    "        if(neuron not in result_dict_comb.keys()): # Initialize the dictionary entry for a neuron not already found\n",
    "            result_dict_comb[neuron] = {}\n",
    "        for ds in list(result_dict[neuron].keys()): # Add the neuropal labels to the combined dictionary\n",
    "            if(ds in ds_of_interest and not (project=='prj_kfc' and (neuron.startswith('SMB')))): # Ignore the SMB neurons in the prj_kfc\n",
    "                result_dict_comb[neuron][ds] = result_dict[neuron][ds]\n",
    "                \n",
    "                \n",
    "    for ds in ds_of_interest:\n",
    "        loaded_data = h5_to_dict(os.path.join(prj_vals[\"processed_h5_directory\"], ds + \"-data.h5\"))\n",
    "        if(not 'pumping' in loaded_data['behavior'].keys()):\n",
    "            continue\n",
    "        data[ds] = {}\n",
    "        data[ds]['neuron_traces'] =  loaded_data['gcamp']['trace_array'] \n",
    "        data[ds]['velocity'] =  loaded_data['behavior']['velocity'] / v_STD\n",
    "        data[ds]['head_angle'] = loaded_data['behavior']['head_angle'] / θh_STD * (-1 if prj_vals['structured_dict'][ds]['Flipped'] else 1)\n",
    "        data[ds]['pumping'] = loaded_data['behavior']['pumping'] / P_STD\n",
    "        data[ds]['reversal_events'] = loaded_data['behavior']['reversal_events'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all neuron classes with DV pairs. Parse out only Ventral neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_dv_classes = {}\n",
    "\n",
    "for neuron in result_dict_comb:\n",
    "    if(len(neuron) < 4):\n",
    "        continue\n",
    "    if(neuron[3] in \"V\"):\n",
    "        if(neuron[-1] in \"LR\"):\n",
    "            if(neuron[:3] in neuron_dv_classes):\n",
    "                neuron_dv_classes[neuron[:3]][neuron[-1]].append(neuron)\n",
    "            else:\n",
    "                neuron_dv_classes[neuron[:3]] = {'L': [], 'R': []}\n",
    "                neuron_dv_classes[neuron[:3]][neuron[-1]].append(neuron)\n",
    "        else:\n",
    "            if(neuron[:3] in neuron_dv_classes):\n",
    "                neuron_dv_classes[neuron[:3]].append(neuron)\n",
    "            else:\n",
    "                neuron_dv_classes[neuron[:3]] = [neuron]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection(lsts):\n",
    "    if(len(lsts) > 2):\n",
    "        return list(set(lsts[0]) & set(intersection(lsts[1:])))\n",
    "    else:\n",
    "        return list(set(lsts[0]) & set(lsts[1]))\n",
    "    \n",
    "def union(lsts):\n",
    "    if(len(lsts) > 2):\n",
    "        return list(set(lsts[0]) | set(union(lsts[1:])))\n",
    "    else:\n",
    "        return list(set(lsts[0]) | set(lsts[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the time_ranges events of interest in each dataset\n",
    "\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "\n",
    "time_range = 12\n",
    "offset = 0\n",
    "max_shift = 0\n",
    "min_reversal_len = time_range + offset\n",
    "\n",
    "decoding_data = {}\n",
    "\n",
    "result_dict = result_dict_comb\n",
    "\n",
    "# Go through datasets and find all reversals that are long enough and have enough data before and after\n",
    "for ds in data.keys():\n",
    "    reversal_starts = []\n",
    "    reversal_ends = []\n",
    "    turns = []\n",
    "    \n",
    "    for reversal in data[ds]['reversal_events']:\n",
    "        if(reversal[1] - reversal[0] >= min_reversal_len and reversal[1]+2 < len(data[ds]['head_angle'])):        \n",
    "            post_reversal_turn = \"D\" if np.mean([data[ds]['head_angle'][reversal[1]+1], data[ds]['head_angle'][reversal[1]+2]]) > 0 else \"V\" # Determine the turn after the reversal\n",
    "            reversal_starts.append(reversal[0] - offset + time_range)\n",
    "            reversal_ends.append(reversal[1] - offset)\n",
    "            \n",
    "            \n",
    "            turns.append(post_reversal_turn)\n",
    "        \n",
    "    data[ds]['reversal_starts'] = reversal_starts\n",
    "    data[ds]['reversal_ends'] = reversal_ends\n",
    "    data[ds]['all_turns'] = turns\n",
    "    \n",
    "    # if(\"D\" not in turns):\n",
    "    #     print(f\"Warning: No dorsal turns detected in {ds}\")\n",
    "    #     data[ds]['reversal_starts'] = []\n",
    "    #     data[ds]['reversal_ends'] = []\n",
    "    #     data[ds]['all_turns'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: CEPV Turns:  380 (D:   62, V:  318)\n",
      "Class: IL1V Turns:  364 (D:   63, V:  301)\n",
      "Class: IL2V Turns:  379 (D:   64, V:  315)\n",
      "Class: OLQV Turns:  375 (D:   58, V:  317)\n",
      "Class: RMDV Turns:  341 (D:   56, V:  285)\n",
      "Class: RMEV Turns:  235 (D:   43, V:  192)\n",
      "Class: SAAV Turns:  340 (D:   54, V:  286)\n",
      "Class: SIAV Turns:  277 (D:   44, V:  233)\n",
      "Class: SIBV Turns:  243 (D:   36, V:  207)\n",
      "Class: SMBV Turns:  302 (D:   51, V:  251)\n",
      "Class: SMDV Turns:  393 (D:   64, V:  329)\n",
      "Class: URAV Turns:  273 (D:   44, V:  229)\n",
      "Class: URYV Turns:  393 (D:   64, V:  329)\n"
     ]
    }
   ],
   "source": [
    "# Extract neuron activation and head curvature data for each event of interest\n",
    "\n",
    "for dv_class in neuron_dv_classes:\n",
    "    if(isinstance(neuron_dv_classes[dv_class], list)):\n",
    "        datasets = list(result_dict_comb[neuron_dv_classes[dv_class][0]].keys())\n",
    "    else:\n",
    "        L_datasets = list(result_dict_comb[neuron_dv_classes[dv_class][\"L\"][0]].keys())\n",
    "        R_datasets = list(result_dict_comb[neuron_dv_classes[dv_class][\"R\"][0]].keys())\n",
    "        datasets = union([L_datasets, R_datasets])\n",
    "    # print(f\"{dv_class}V {datasets}\")\n",
    "    \n",
    "    n_valid_turns = 0\n",
    "    \n",
    "    # Go through datasets and find all reversals that are long enough and have enough data before and after\n",
    "    for ds in datasets:\n",
    "        n_valid_turns += len(data[ds]['all_turns'])\n",
    "        \n",
    "    all_turns = []\n",
    "    reversal_start_neuron_data = np.zeros((n_valid_turns, time_range, 3))\n",
    "    reversal_end_neuron_data = np.zeros((n_valid_turns, time_range, 3))\n",
    "    \n",
    "    for source, neuron_data_arr in zip([\"start\", \"end\"], [reversal_start_neuron_data, reversal_end_neuron_data]):\n",
    "        # Go through datasets and extract the neural data for each reversal event\n",
    "        idx = 0\n",
    "        for ds in datasets:\n",
    "            t_events = data[ds][f'reversal_{source}s']\n",
    "        \n",
    "            for i, t_event in enumerate(t_events):\n",
    "                # Extract the head curvature data\n",
    "                head_curv = data[ds]['head_angle'][t_event-time_range:t_event] \n",
    "                \n",
    "                if(isinstance(neuron_dv_classes[dv_class], list)):\n",
    "                    # If the neuron doesn't have a left and right neuron, just use the one neuron\n",
    "                    neuron_data = data[ds]['neuron_traces'][t_event-time_range:t_event, result_dict[neuron_dv_classes[dv_class][0]][ds][\"index\"]-1]\n",
    "                else:\n",
    "                    # If the neuron is present in both the left and right neurons, randomly choose one. Otherwise, use the one that is present\n",
    "                    neuron_data = np.zeros((time_range))\n",
    "                    if(ds in result_dict[neuron_dv_classes[dv_class]['L'][0]]):\n",
    "                        neuron_data_L = data[ds]['neuron_traces'][t_event-time_range:t_event, result_dict[neuron_dv_classes[dv_class]['L'][0]][ds][\"index\"]-1]\n",
    "                        neuron_data = neuron_data_L\n",
    "                    if(ds in result_dict[neuron_dv_classes[dv_class]['R'][0]]):\n",
    "                        neuron_data_R = data[ds]['neuron_traces'][t_event-time_range:t_event, result_dict[neuron_dv_classes[dv_class]['R'][0]][ds][\"index\"]-1]\n",
    "                        neuron_data = neuron_data_R\n",
    "                    if(ds in result_dict[neuron_dv_classes[dv_class]['L'][0]] and ds in result_dict[neuron_dv_classes[dv_class]['R'][0]]):\n",
    "                        # Both L and R are detected. Randomly choose between the left and right neurons\n",
    "                        key, sk = jax.random.split(key)\n",
    "                        neuron_data = neuron_data_L if 0.5 < jax.random.uniform(sk, (1,)) else neuron_data_R \n",
    "                    \n",
    "                # Stack the neural data and head curvature data\n",
    "                neuron_data_arr[idx] = np.stack([neuron_data, head_curv, np.zeros((time_range))], axis=1) \n",
    "                    \n",
    "                # Append the turn direction\n",
    "                all_turns.append(data[ds]['all_turns'][i])\n",
    "                idx += 1\n",
    "    \n",
    "    ventral_turn_start = []\n",
    "    dorsal_turn_start = []\n",
    "\n",
    "    ventral_turn_end = []\n",
    "    dorsal_turn_end = []\n",
    "\n",
    "    # Reformat the data into a format that can be used for decoding\n",
    "    for (turn, start_value, end_value) in zip(all_turns, reversal_start_neuron_data, reversal_end_neuron_data):\n",
    "        if(turn == \"V\"):\n",
    "            ventral_turn_start.append(start_value)\n",
    "            ventral_turn_end.append(end_value)\n",
    "        elif(turn == \"D\"):\n",
    "            dorsal_turn_start.append(start_value)\n",
    "            dorsal_turn_end.append(end_value)\n",
    "            \n",
    "    ventral_turn_start = jnp.array(ventral_turn_start)\n",
    "    dorsal_turn_start = jnp.array(dorsal_turn_start)\n",
    "\n",
    "    ventral_turn_end = jnp.array(ventral_turn_end)\n",
    "    dorsal_turn_end = jnp.array(dorsal_turn_end)\n",
    "    \n",
    "    # Print out some stats\n",
    "    # print(f\"Class: {dv_class}V Detections: {len(datasets):2d} Turns: {n_valid_turns:4d} (D: {dorsal_turn_start.shape[0]:4d}, V: {ventral_turn_start.shape[0]:4d})\")\n",
    "    print(f\"Class: {dv_class}V Turns: {n_valid_turns:4d} (D: {dorsal_turn_start.shape[0]:4d}, V: {ventral_turn_start.shape[0]:4d})\")\n",
    "\n",
    "    decoding_data[dv_class] = {}\n",
    "\n",
    "    decoding_data[dv_class]['ventral_turn_start'] = ventral_turn_start\n",
    "    decoding_data[dv_class]['dorsal_turn_start'] = dorsal_turn_start\n",
    "    \n",
    "    decoding_data[dv_class]['ventral_turn_end'] = ventral_turn_end\n",
    "    decoding_data[dv_class]['dorsal_turn_end'] = dorsal_turn_end\n",
    "    \n",
    "    # Save to an h5 file\n",
    "    dict_to_h5(f\"/home/alex/data3/prj_rim/Decoding_Data/Finalized/DVPostReversal/turn_predict_{dv_class}V.h5\", decoding_data[dv_class], overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class: CEPV Turns: 1214 (D: 356, V: 858)\n",
      "Class: IL1V Turns:  933 (D: 231, V: 702)\n",
      "Class: IL2V Turns: 1327 (D: 366, V: 961)\n",
      "Class: OLQV Turns: 1330 (D: 364, V: 966)\n",
      "Class: RMDV Turns: 1314 (D: 369, V: 945)\n",
      "Class: RMEV Turns:  909 (D: 263, V: 646)\n",
      "Class: SAAV Turns:  932 (D: 240, V: 692)\n",
      "Class: SIAV Turns:  258 (D:  43, V: 215)\n",
      "Class: SIBV Turns:  209 (D:  39, V: 170)\n",
      "Class: SMBV Turns:  321 (D:  72, V: 249)\n",
      "Class: SMDV Turns: 1320 (D: 374, V: 946)\n",
      "Class: URAV Turns:  644 (D: 197, V: 447)\n",
      "Class: URYV Turns: 1347 (D: 362, V: 985)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Before added data and fixed labels\n",
    "print(\"\"\"\n",
    "Class: CEPV Turns: 1214 (D: 356, V: 858)\n",
    "Class: IL1V Turns:  933 (D: 231, V: 702)\n",
    "Class: IL2V Turns: 1327 (D: 366, V: 961)\n",
    "Class: OLQV Turns: 1330 (D: 364, V: 966)\n",
    "Class: RMDV Turns: 1314 (D: 369, V: 945)\n",
    "Class: RMEV Turns:  909 (D: 263, V: 646)\n",
    "Class: SAAV Turns:  932 (D: 240, V: 692)\n",
    "Class: SIAV Turns:  258 (D:  43, V: 215)\n",
    "Class: SIBV Turns:  209 (D:  39, V: 170)\n",
    "Class: SMBV Turns:  321 (D:  72, V: 249)\n",
    "Class: SMDV Turns: 1320 (D: 374, V: 946)\n",
    "Class: URAV Turns:  644 (D: 197, V: 447)\n",
    "Class: URYV Turns: 1347 (D: 362, V: 985)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CePNEM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
